---
description: Docker best practices for Node.js microservices in small business websites
alwaysApply: false
---

# Docker Guidelines for Node.js Microservices

## Overview

These guidelines provide best practices for containerizing Node.js microservices for small business websites. Focus on simplicity, security, maintainability, and cost-effectiveness while following industry standards.

## Dockerfile Best Practices

### Multi-Stage Builds

Always use multi-stage builds to reduce image size and improve security:

```dockerfile
# Stage 1: Dependencies
FROM node:20-alpine AS deps
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force

# Stage 2: Build (if needed)
FROM node:20-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

# Stage 3: Runtime
FROM node:20-alpine AS runner
WORKDIR /app

# Create non-root user
RUN addgroup --system --gid 1001 nodejs && \
    adduser --system --uid 1001 nodejs

# Copy only production dependencies
COPY --from=deps --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nodejs:nodejs /app/dist ./dist
COPY --chown=nodejs:nodejs package*.json ./

USER nodejs

EXPOSE 3000

ENV NODE_ENV=production
CMD ["node", "dist/index.js"]
```

### Base Image Selection

- **Use Alpine Linux**: `node:20-alpine` for smaller images (~40MB vs ~900MB)
- **Pin specific versions**: Use `node:20.11.0-alpine` instead of `node:20-alpine` for reproducibility
- **Use LTS versions**: Prefer Node.js LTS versions (18.x, 20.x)
- **Avoid**: `node:latest` or unversioned tags in production

### Layer Caching Optimization

Order Dockerfile instructions from least to most frequently changing:

```dockerfile
# 1. Base image (changes rarely)
FROM node:20-alpine

# 2. Install system dependencies (changes rarely)
RUN apk add --no-cache dumb-init

# 3. Set working directory (changes rarely)
WORKDIR /app

# 4. Copy dependency files (changes less frequently)
COPY package*.json ./

# 5. Install dependencies (changes when package.json changes)
RUN npm ci --only=production

# 6. Copy application code (changes most frequently)
COPY . .

# 7. Set runtime configuration (changes rarely)
ENV NODE_ENV=production
USER nodejs
EXPOSE 3000
CMD ["dumb-init", "node", "index.js"]
```

### Security Practices

1. **Run as non-root user**:
   ```dockerfile
   RUN addgroup --system --gid 1001 nodejs && \
       adduser --system --uid 1001 nodejs
   USER nodejs
   ```

2. **Use minimal base images**: Alpine Linux reduces attack surface

3. **Scan for vulnerabilities**: Use `docker scan` or tools like Trivy/Snyk

4. **Don't expose secrets**: Use environment variables or secrets management

5. **Keep images updated**: Regularly update base images and dependencies

6. **Use `.dockerignore`**: Prevent sensitive files from being copied

### .dockerignore File

Always include a `.dockerignore` file:

```
node_modules
npm-debug.log
.env
.env.local
.env.*.local
.git
.gitignore
README.md
.vscode
.idea
*.md
.DS_Store
coverage
.nyc_output
dist
build
*.log
docker-compose*.yml
Dockerfile*
```

## Microservices Architecture Patterns

### Service Organization

```
project-root/
├── services/
│   ├── api-gateway/
│   │   ├── Dockerfile
│   │   ├── package.json
│   │   └── src/
│   ├── auth-service/
│   │   ├── Dockerfile
│   │   ├── package.json
│   │   └── src/
│   ├── booking-service/
│   │   ├── Dockerfile
│   │   ├── package.json
│   │   └── src/
│   └── notification-service/
│       ├── Dockerfile
│       ├── package.json
│       └── src/
├── docker-compose.yml
└── docker-compose.prod.yml
```

### Service-Specific Dockerfiles

Each microservice should have its own Dockerfile optimized for its needs:

**Example: API Service**
```dockerfile
FROM node:20-alpine AS deps
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

FROM node:20-alpine AS runner
WORKDIR /app
RUN addgroup --system --gid 1001 nodejs && \
    adduser --system --uid 1001 nodejs
COPY --from=deps --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --chown=nodejs:nodejs . .
USER nodejs
EXPOSE 3000
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js
CMD ["node", "index.js"]
```

## Docker Compose Configuration

### Development Docker Compose

```yaml
version: '3.8'

services:
  # API Gateway
  api-gateway:
    build:
      context: ./services/api-gateway
      dockerfile: Dockerfile.dev
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://user:pass@db:5432/nailsalon
      - REDIS_URL=redis://redis:6379
    volumes:
      - ./services/api-gateway:/app
      - /app/node_modules
    depends_on:
      - db
      - redis
    networks:
      - app-network

  # Auth Service
  auth-service:
    build:
      context: ./services/auth-service
      dockerfile: Dockerfile.dev
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://user:pass@db:5432/nailsalon
      - JWT_SECRET=dev-secret-change-in-prod
    volumes:
      - ./services/auth-service:/app
      - /app/node_modules
    depends_on:
      - db
    networks:
      - app-network

  # Booking Service
  booking-service:
    build:
      context: ./services/booking-service
      dockerfile: Dockerfile.dev
    ports:
      - "3002:3002"
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://user:pass@db:5432/nailsalon
    volumes:
      - ./services/booking-service:/app
      - /app/node_modules
    depends_on:
      - db
    networks:
      - app-network

  # Database
  db:
    image: postgres:16-alpine
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=nailsalon
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

volumes:
  postgres-data:
  redis-data:

networks:
  app-network:
    driver: bridge
```

### Production Docker Compose

```yaml
version: '3.8'

services:
  api-gateway:
    build:
      context: ./services/api-gateway
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M

  auth-service:
    build:
      context: ./services/auth-service
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - JWT_SECRET=${JWT_SECRET}
    depends_on:
      db:
        condition: service_healthy
    networks:
      - app-network

  booking-service:
    build:
      context: ./services/booking-service
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
    depends_on:
      db:
        condition: service_healthy
    networks:
      - app-network

  db:
    image: postgres:16-alpine
    restart: unless-stopped
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    volumes:
      - redis-data:/data
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

volumes:
  postgres-data:
  redis-data:

networks:
  app-network:
    driver: bridge
```

## Environment Management

### Environment Variables

1. **Use `.env` files for local development**:
   ```bash
   # .env.example (commit to git)
   DATABASE_URL=postgresql://user:pass@localhost:5432/nailsalon
   REDIS_URL=redis://localhost:6379
   JWT_SECRET=change-me-in-production
   NODE_ENV=development
   ```

2. **Never commit `.env` files** with real secrets

3. **Use Docker secrets** for production (Docker Swarm) or environment variables from secure sources

4. **Validate required environment variables** at startup:
   ```javascript
   const requiredEnvVars = ['DATABASE_URL', 'JWT_SECRET'];
   const missing = requiredEnvVars.filter(key => !process.env[key]);
   if (missing.length > 0) {
     throw new Error(`Missing required environment variables: ${missing.join(', ')}`);
   }
   ```

## Health Checks

### Implement Health Check Endpoints

```javascript
// healthcheck.js
const http = require('http');

const options = {
  host: 'localhost',
  port: process.env.PORT || 3000,
  path: '/health',
  timeout: 2000
};

const request = http.request(options, (res) => {
  console.log(`Health check status: ${res.statusCode}`);
  if (res.statusCode === 200) {
    process.exit(0);
  } else {
    process.exit(1);
  }
});

request.on('error', (err) => {
  console.error('Health check failed:', err);
  process.exit(1);
});

request.end();
```

### Dockerfile Health Check

```dockerfile
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js
```

### Application Health Endpoint

```javascript
// Express example
app.get('/health', async (req, res) => {
  try {
    // Check database connection
    await db.query('SELECT 1');
    
    // Check Redis connection
    await redis.ping();
    
    res.status(200).json({
      status: 'healthy',
      timestamp: new Date().toISOString(),
      uptime: process.uptime()
    });
  } catch (error) {
    res.status(503).json({
      status: 'unhealthy',
      error: error.message
    });
  }
});
```

## Logging Best Practices

### Structured Logging

1. **Use JSON logs** for better parsing:
   ```javascript
   const logger = {
     info: (message, meta = {}) => {
       console.log(JSON.stringify({
         level: 'info',
         message,
         timestamp: new Date().toISOString(),
         ...meta
       }));
     },
     error: (message, error, meta = {}) => {
       console.error(JSON.stringify({
         level: 'error',
         message,
         error: error?.message,
         stack: error?.stack,
         timestamp: new Date().toISOString(),
         ...meta
       }));
     }
   };
   ```

2. **Log to stdout/stderr**: Docker captures these automatically

3. **Avoid logging sensitive data**: Never log passwords, tokens, or PII

4. **Use log levels appropriately**: debug, info, warn, error

### Docker Logging Configuration

```yaml
services:
  api-gateway:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
```

## Resource Limits

### Set Resource Constraints

```yaml
services:
  api-gateway:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
```

**Small Business Recommendations**:
- **API Services**: 512MB-1GB RAM, 0.5-1 CPU
- **Database**: 1-2GB RAM, 1 CPU
- **Cache (Redis)**: 256MB-512MB RAM, 0.25 CPU

## Networking

### Service-to-Service Communication

1. **Use service names** in Docker Compose for internal communication:
   ```javascript
   const dbUrl = process.env.DATABASE_URL || 'postgresql://user:pass@db:5432/nailsalon';
   ```

2. **Don't expose unnecessary ports** to host machine in production

3. **Use internal networks** for service communication:
   ```yaml
   networks:
     app-network:
       driver: bridge
       internal: false  # Set to true if no external access needed
   ```

4. **API Gateway pattern**: Expose only the gateway to external traffic

## Volume Management

### Named Volumes for Data Persistence

```yaml
volumes:
  postgres-data:
    driver: local
  redis-data:
    driver: local
```

### Bind Mounts for Development Only

```yaml
# Development only
volumes:
  - ./services/api-gateway:/app
  - /app/node_modules  # Prevent overwriting node_modules
```

## Development Workflow

### Development Dockerfile

```dockerfile
FROM node:20-alpine

WORKDIR /app

# Install dependencies including devDependencies
COPY package*.json ./
RUN npm install

# Copy source code
COPY . .

# Expose port
EXPOSE 3000

# Use nodemon or similar for hot reload
CMD ["npm", "run", "dev"]
```

### Useful Docker Commands

```bash
# Build images
docker-compose build

# Start services
docker-compose up -d

# View logs
docker-compose logs -f [service-name]

# Execute commands in container
docker-compose exec [service-name] sh

# Stop services
docker-compose down

# Remove volumes (careful - deletes data)
docker-compose down -v

# Rebuild specific service
docker-compose build [service-name]
docker-compose up -d [service-name]
```

## Production Deployment

### Build for Production

```bash
# Build production images
docker-compose -f docker-compose.prod.yml build

# Tag for registry
docker tag nailsalon-api-gateway:latest registry.example.com/nailsalon-api-gateway:v1.0.0

# Push to registry
docker push registry.example.com/nailsalon-api-gateway:v1.0.0
```

### Production Checklist

- [ ] Use multi-stage builds
- [ ] Run as non-root user
- [ ] Set resource limits
- [ ] Configure health checks
- [ ] Set up logging
- [ ] Use secrets management
- [ ] Enable restart policies
- [ ] Configure backups for volumes
- [ ] Set up monitoring
- [ ] Use reverse proxy (nginx/traefik)
- [ ] Enable HTTPS/TLS
- [ ] Set up CI/CD pipeline

## Small Business Optimization Tips

### Cost Optimization

1. **Use Alpine images**: Smaller images = less storage and faster pulls
2. **Multi-stage builds**: Reduce final image size
3. **Resource limits**: Prevent resource waste
4. **Consolidate services**: For small businesses, consider fewer microservices initially
5. **Use Docker Hub free tier** or self-hosted registry

### Simplified Architecture

For small businesses, start simple:
- **Monorepo with separate services** (easier to manage)
- **Single Docker Compose file** for all services
- **Shared database** (upgrade to separate DBs when scaling)
- **Single network** for all services

### Scaling Considerations

When ready to scale:
1. **Horizontal scaling**: Run multiple instances with load balancer
2. **Service separation**: Split database by service if needed
3. **Caching layer**: Add Redis for frequently accessed data
4. **CDN**: Use CDN for static assets
5. **Container orchestration**: Consider Kubernetes only if needed (Docker Swarm is simpler)

## Troubleshooting

### Common Issues

1. **Port already in use**:
   ```bash
   # Find process using port
   lsof -i :3000
   # Kill process or change port in docker-compose.yml
   ```

2. **Container keeps restarting**:
   ```bash
   # Check logs
   docker-compose logs [service-name]
   # Check health check status
   docker ps
   ```

3. **Out of memory**:
   ```bash
   # Check container resource usage
   docker stats
   # Adjust memory limits in docker-compose.yml
   ```

4. **Database connection errors**:
   - Ensure database service is healthy
   - Check network connectivity
   - Verify environment variables

## Testing in Docker

### Test Dockerfiles

```dockerfile
# Dockerfile.test
FROM node:20-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci

COPY . .

CMD ["npm", "test"]
```

### Run Tests in Container

```bash
docker-compose run --rm api-gateway npm test
```

## Best Practices Summary

✅ **DO**:
- Use multi-stage builds
- Run as non-root user
- Use Alpine base images
- Set resource limits
- Implement health checks
- Use .dockerignore
- Pin image versions
- Structure layers for caching
- Use named volumes for data
- Log to stdout/stderr
- Validate environment variables

❌ **DON'T**:
- Expose secrets in Dockerfiles
- Use `latest` tags in production
- Run as root user
- Copy entire project before installing dependencies
- Commit .env files with secrets
- Expose unnecessary ports
- Use bind mounts in production
- Ignore health checks
- Skip resource limits
- Log sensitive information

## Additional Resources

- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)
- [Node.js Docker Best Practices](https://github.com/nodejs/docker-node/blob/main/docs/BestPractices.md)
- [Docker Security](https://docs.docker.com/engine/security/)
- [Multi-stage builds](https://docs.docker.com/build/building/multi-stage/)
